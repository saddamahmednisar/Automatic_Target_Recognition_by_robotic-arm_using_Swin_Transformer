{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "671d0051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import scipy.io\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e70c556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/a30/anaconda3/envs/mughees_exp/lib/python3.8/site-packages/cv2/../../../../lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "# conda environments:\n",
      "#\n",
      "base                     /home/a30/anaconda3\n",
      "mughees_exp           *  /home/a30/anaconda3/envs/mughees_exp\n",
      "mughees_tf               /home/a30/anaconda3/envs/mughees_tf\n",
      "tf-gpu-cuda10            /home/a30/anaconda3/envs/tf-gpu-cuda10\n",
      "torchDL                  /home/a30/anaconda3/envs/torchDL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "634fb6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/a30/anaconda3/envs/mughees_exp/lib/python3.8/site-packages/cv2/../../../../lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "# packages in environment at /home/a30/anaconda3/envs/mughees_exp:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "opencv                    4.6.0            py38hd653453_2  \n"
     ]
    }
   ],
   "source": [
    "!conda list opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e940e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "\n",
    "#from tensorflow import keras\n",
    "#from tensorflow.keras import layers\n",
    "#import tensorflow_addons as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import scipy.io\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6791a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda list opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f221c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebca4610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting tar files found inside main zip file\n",
    "#shutil.unpack_archive(\"101_ObjectCategories.tar.gz\", \"/\")\n",
    "#shutil.unpack_archive(\"Annotations.tar\", \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af23082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to images and annotations\n",
    "path_images = \"/home/a30/Desktop/drone_research_group/transformer/labeled dataset cube/images/\"\n",
    "path_annot = \"/home/a30/Desktop/drone_research_group/transformer/labeled dataset cube/output/\"\n",
    "\n",
    "#path_to_downloaded_file = keras.utils.get_file(\n",
    " #   fname=\"caltech_101_zipped\",\n",
    "  #  origin=\"https://data.caltech.edu/records/mzrjq-6wc02/files/caltech-101.zip\",\n",
    "   # extract=True,\n",
    "    #archive_format=\"zip\",  # downloaded file format\n",
    "    #cache_dir=\"/\",  # cache and extract in current directory\n",
    "#)\n",
    "\n",
    "# Extracting tar files found inside main zip file\n",
    "#shutil.unpack_archive(\"101_ObjectCategories.tar.gz\", \"/\")\n",
    "#shutil.unpack_archive(\"Annotations.tar\", \"/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902130a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to images and annotations\n",
    "path_images = \"101_ObjectCategories/airplanes/\"\n",
    "path_annot = \"Annotations/Airplanes_Side_2/\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# list of paths to images and annotations\n",
    "image_paths = [\n",
    "    f for f in os.listdir(path_images) if os.path.isfile(os.path.join(path_images, f))\n",
    "]\n",
    "annot_paths = [\n",
    "    f for f in os.listdir(path_annot) if os.path.isfile(os.path.join(path_annot, f))\n",
    "]\n",
    "\n",
    "image_paths.sort()\n",
    "annot_paths.sort()\n",
    "\n",
    "image_size = 224  # resize input images to this size\n",
    "\n",
    "images, targets = [], []\n",
    "\n",
    "# loop over the annotations and images, preprocess them and store in lists\n",
    "for i in range(0, len(annot_paths)):\n",
    "    # Access bounding box coordinates\n",
    "    annot = scipy.io.loadmat(path_annot + annot_paths[i])[\"box_coord\"][0]\n",
    "\n",
    "    top_left_x, top_left_y = annot[2], annot[0]\n",
    "    bottom_right_x, bottom_right_y = annot[3], annot[1]\n",
    "\n",
    "    image = keras.utils.load_img(\n",
    "        path_images + image_paths[i],\n",
    "    )\n",
    "    (w, h) = image.size[:2]\n",
    "\n",
    "    # resize train set images\n",
    "    if i < int(len(annot_paths) * 0.8):\n",
    "        # resize image if it is for training dataset\n",
    "        image = image.resize((image_size, image_size))\n",
    "\n",
    "    # convert image to array and append to list\n",
    "    images.append(keras.utils.img_to_array(image))\n",
    "\n",
    "    # apply relative scaling to bounding boxes as per given image and append to list\n",
    "    targets.append(\n",
    "        (\n",
    "            float(top_left_x) / w,\n",
    "            float(top_left_y) / h,\n",
    "            float(bottom_right_x) / w,\n",
    "            float(bottom_right_y) / h,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Convert the list to numpy array, split to train and test dataset\n",
    "(x_train), (y_train) = (\n",
    "    np.asarray(images[: int(len(images) * 0.8)]),\n",
    "    np.asarray(targets[: int(len(targets) * 0.8)]),\n",
    ")\n",
    "(x_test), (y_test) = (\n",
    "    np.asarray(images[int(len(images) * 0.8) :]),\n",
    "    np.asarray(targets[int(len(targets) * 0.8) :]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6e0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04a3ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7b9a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    #     Override function to avoid error while saving model\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update(\n",
    "            {\n",
    "                \"input_shape\": input_shape,\n",
    "                \"patch_size\": patch_size,\n",
    "                \"num_patches\": num_patches,\n",
    "                \"projection_dim\": projection_dim,\n",
    "                \"num_heads\": num_heads,\n",
    "                \"transformer_units\": transformer_units,\n",
    "                \"transformer_layers\": transformer_layers,\n",
    "                \"mlp_head_units\": mlp_head_units,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        # return patches\n",
    "        return tf.reshape(patches, [batch_size, -1, patches.shape[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653f32d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 32  # Size of the patches to be extracted from the input images\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(x_train[0].astype(\"uint8\"))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "patches = Patches(patch_size)(tf.convert_to_tensor([x_train[0]]))\n",
    "print(f\"Image size: {image_size} X {image_size}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"{patches.shape[1]} patches per image \\n{patches.shape[-1]} elements per patch\")\n",
    "\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9642e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    # Override function to avoid error while saving model\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update(\n",
    "            {\n",
    "                \"input_shape\": input_shape,\n",
    "                \"patch_size\": patch_size,\n",
    "                \"num_patches\": num_patches,\n",
    "                \"projection_dim\": projection_dim,\n",
    "                \"num_heads\": num_heads,\n",
    "                \"transformer_units\": transformer_units,\n",
    "                \"transformer_layers\": transformer_layers,\n",
    "                \"mlp_head_units\": mlp_head_units,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947dea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_object_detector(\n",
    "    input_shape,\n",
    "    patch_size,\n",
    "    num_patches,\n",
    "    projection_dim,\n",
    "    num_heads,\n",
    "    transformer_units,\n",
    "    transformer_layers,\n",
    "    mlp_head_units,\n",
    "):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Create patches\n",
    "    patches = Patches(patch_size)(inputs)\n",
    "    # Encode patches\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.3)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.3)\n",
    "\n",
    "    bounding_box = layers.Dense(4)(\n",
    "        features\n",
    "    )  # Final four neurons that output bounding box\n",
    "\n",
    "    # return Keras model.\n",
    "    return keras.Model(inputs=inputs, outputs=bounding_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a90108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, learning_rate, weight_decay, batch_size, num_epochs):\n",
    "\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    # Compile model.\n",
    "    model.compile(optimizer=optimizer, loss=keras.losses.MeanSquaredError())\n",
    "\n",
    "    checkpoint_filepath = \"logs/\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[\n",
    "            checkpoint_callback,\n",
    "            keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "input_shape = (image_size, image_size, 3)  # input image shape\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "# Size of the transformer layers\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]\n",
    "transformer_layers = 4\n",
    "mlp_head_units = [2048, 1024, 512, 64, 32]  # Size of the dense layers\n",
    "\n",
    "\n",
    "history = []\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "\n",
    "vit_object_detector = create_vit_object_detector(\n",
    "    input_shape,\n",
    "    patch_size,\n",
    "    num_patches,\n",
    "    projection_dim,\n",
    "    num_heads,\n",
    "    transformer_units,\n",
    "    transformer_layers,\n",
    "    mlp_head_units,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = run_experiment(\n",
    "    vit_object_detector, learning_rate, weight_decay, batch_size, num_epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9061ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "# Saves the model in current path\n",
    "vit_object_detector.save(\"vit_object_detector.h5\", save_format=\"h5\")\n",
    "\n",
    "# To calculate IoU (intersection over union, given two bounding boxes)\n",
    "def bounding_box_intersection_over_union(box_predicted, box_truth):\n",
    "    # get (x, y) coordinates of intersection of bounding boxes\n",
    "    top_x_intersect = max(box_predicted[0], box_truth[0])\n",
    "    top_y_intersect = max(box_predicted[1], box_truth[1])\n",
    "    bottom_x_intersect = min(box_predicted[2], box_truth[2])\n",
    "    bottom_y_intersect = min(box_predicted[3], box_truth[3])\n",
    "\n",
    "    # calculate area of the intersection bb (bounding box)\n",
    "    intersection_area = max(0, bottom_x_intersect - top_x_intersect + 1) * max(\n",
    "        0, bottom_y_intersect - top_y_intersect + 1\n",
    "    )\n",
    "\n",
    "    # calculate area of the prediction bb and ground-truth bb\n",
    "    box_predicted_area = (box_predicted[2] - box_predicted[0] + 1) * (\n",
    "        box_predicted[3] - box_predicted[1] + 1\n",
    "    )\n",
    "    box_truth_area = (box_truth[2] - box_truth[0] + 1) * (\n",
    "        box_truth[3] - box_truth[1] + 1\n",
    "    )\n",
    "\n",
    "    # calculate intersection over union by taking intersection\n",
    "    # area and dividing it by the sum of predicted bb and ground truth\n",
    "    # bb areas subtracted by  the interesection area\n",
    "\n",
    "    # return ioU\n",
    "    return intersection_area / float(\n",
    "        box_predicted_area + box_truth_area - intersection_area\n",
    "    )\n",
    "\n",
    "i, mean_iou = 0, 0\n",
    "\n",
    "# Compare results for 10 images in the test set\n",
    "for input_image in x_test[:10]:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 15))\n",
    "    im = input_image\n",
    "\n",
    "    # Display the image\n",
    "    ax1.imshow(im.astype(\"uint8\"))\n",
    "    ax2.imshow(im.astype(\"uint8\"))\n",
    "\n",
    "    input_image = cv2.resize(\n",
    "        input_image, (image_size, image_size), interpolation=cv2.INTER_AREA\n",
    "    )\n",
    "    input_image = np.expand_dims(input_image, axis=0)\n",
    "    preds = vit_object_detector.predict(input_image)[0]\n",
    "\n",
    "    (h, w) = (im).shape[0:2]\n",
    "\n",
    "    top_left_x, top_left_y = int(preds[0] * w), int(preds[1] * h)\n",
    "\n",
    "    bottom_right_x, bottom_right_y = int(preds[2] * w), int(preds[3] * h)\n",
    "\n",
    "    box_predicted = [top_left_x, top_left_y, bottom_right_x, bottom_right_y]\n",
    "    # Create the bounding box\n",
    "    rect = patches.Rectangle(\n",
    "        (top_left_x, top_left_y),\n",
    "        bottom_right_x - top_left_x,\n",
    "        bottom_right_y - top_left_y,\n",
    "        facecolor=\"none\",\n",
    "        edgecolor=\"red\",\n",
    "        linewidth=1,\n",
    "    )\n",
    "    # Add the bounding box to the image\n",
    "    ax1.add_patch(rect)\n",
    "    ax1.set_xlabel(\n",
    "        \"Predicted: \"\n",
    "        + str(top_left_x)\n",
    "        + \", \"\n",
    "        + str(top_left_y)\n",
    "        + \", \"\n",
    "        + str(bottom_right_x)\n",
    "        + \", \"\n",
    "        + str(bottom_right_y)\n",
    "    )\n",
    "\n",
    "    top_left_x, top_left_y = int(y_test[i][0] * w), int(y_test[i][1] * h)\n",
    "\n",
    "    bottom_right_x, bottom_right_y = int(y_test[i][2] * w), int(y_test[i][3] * h)\n",
    "\n",
    "    box_truth = top_left_x, top_left_y, bottom_right_x, bottom_right_y\n",
    "\n",
    "    mean_iou += bounding_box_intersection_over_union(box_predicted, box_truth)\n",
    "    # Create the bounding box\n",
    "    rect = patches.Rectangle(\n",
    "        (top_left_x, top_left_y),\n",
    "        bottom_right_x - top_left_x,\n",
    "        bottom_right_y - top_left_y,\n",
    "        facecolor=\"none\",\n",
    "        edgecolor=\"red\",\n",
    "        linewidth=1,\n",
    "    )\n",
    "    # Add the bounding box to the image\n",
    "    ax2.add_patch(rect)\n",
    "    ax2.set_xlabel(\n",
    "        \"Target: \"\n",
    "        + str(top_left_x)\n",
    "        + \", \"\n",
    "        + str(top_left_y)\n",
    "        + \", \"\n",
    "        + str(bottom_right_x)\n",
    "        + \", \"\n",
    "        + str(bottom_right_y)\n",
    "        + \"\\n\"\n",
    "        + \"IoU\"\n",
    "        + str(bounding_box_intersection_over_union(box_predicted, box_truth))\n",
    "    )\n",
    "    i = i + 1\n",
    "\n",
    "print(\"mean_iou: \" + str(mean_iou / len(x_test[:10])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d08370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mughees_exp",
   "language": "python",
   "name": "mughees_exp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
